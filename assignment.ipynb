{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1kxzuvBYl0e"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NE_fTbKGe5z",
        "outputId": "41d8a998-c9c9-49c0-c753-ce6b03f90d93"
      },
      "outputs": [],
      "source": [
        "#Load packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "# Importing Data loading functions. Uncomment the one you want to use\n",
        "from worcliver.load_data import load_data\n",
        "\n",
        "from scipy.stats import ttest_ind, mannwhitneyu, shapiro\n",
        "from statsmodels.stats.multitest import multipletests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "data = load_data()\n",
        "\n",
        "# Configure numerical data\n",
        "# Create a copy of the dataset\n",
        "num_data = data.copy()\n",
        "\n",
        "# Transform labels: benign -> 1, malignant -> 0\n",
        "num_data['label'] = num_data['label'].map({'benign': 1, 'malignant': 0})\n",
        "print(num_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Description of the data\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Display basic info\n",
        "print(\"First five rows of the dataset:\")\n",
        "print(data.head(), \"\\n\")\n",
        "\n",
        "print(\"Dataset info:\")\n",
        "print(data.info(), \"\\n\")\n",
        "\n",
        "print(\"Summary statistics:\")\n",
        "print(data.describe(), \"\\n\")\n",
        "\n",
        "# Counting missing values\n",
        "missing_values = data.isnull().sum()\n",
        "total_missing = missing_values.sum()\n",
        "\n",
        "print(f\"Total missing values in the dataset: {total_missing}\\n\")\n",
        "print(f\"Missing values per column:\\n{missing_values[missing_values > 0]}\\n\")\n",
        "\n",
        "# Counting categorical and numerical columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "numerical_columns = data.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "print(f\"Number of categorical columns: {len(categorical_columns)}\")\n",
        "print(f\"Number of numerical columns: {len(numerical_columns)}\\n\")\n",
        "\n",
        "# Count of each label (benign/malignant)\n",
        "label_counts = data['label'].value_counts()\n",
        "\n",
        "print(\"Label distribution:\")\n",
        "print(label_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure numerical data\n",
        "# Create a copy of the dataset\n",
        "num_data = data.copy()\n",
        "\n",
        "# Transform labels: benign -> 1, malignant -> 0\n",
        "num_data['label'] = num_data['label'].map({'benign': 1, 'malignant': 0})\n",
        "print(num_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Splitting data in test and train set \n",
        "y = num_data['label']\n",
        "x = num_data[:]\n",
        "\n",
        "#x is features, y  = maligne / benign\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "#print the shape of the data sets  \n",
        "print(f'The shape of the train data: {x_train.shape}')\n",
        "print(f'The shape of the test data: {x_test.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Data deviden in bengign and malignant \n",
        "benign = data[data['label'] == 'benign']\n",
        "malignant = data[data['label'] == 'malignant']\n",
        "\n",
        "benign.to_csv('benign_data.csv', index=True)\n",
        "malignant.to_csv('malignant_data.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#statistics \n",
        "# Mean\n",
        "benign_mean = benign.mean(numeric_only=True)\n",
        "malignant_mean = malignant.mean(numeric_only=True)\n",
        "\n",
        "# Standard deviation\n",
        "benign_std = benign.std(numeric_only=True)\n",
        "malignant_std = malignant.std(numeric_only=True)\n",
        "\n",
        "#Print statistics\n",
        "benign_stats = pd.DataFrame({\n",
        "    'mean': benign.mean(numeric_only=True),\n",
        "    'std': benign.std(numeric_only=True)\n",
        "})\n",
        "print(benign_stats)\n",
        "benign_stats.T.to_csv('benign_stats.csv')\n",
        "\n",
        "\n",
        "malignant_stats = pd.DataFrame({\n",
        "    'mean': malignant.mean(numeric_only=True),\n",
        "    'std': malignant.std(numeric_only=True)\n",
        "})\n",
        "malignant_stats.T.to_csv('malignant_stats.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "vscode": {
          "languageId": "perl"
        }
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'statsmodels'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ttest_ind, mannwhitneyu, shapiro\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultitest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multipletests\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Check column names to ensure correct splitting\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mColumns in the dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import ttest_ind, mannwhitneyu, shapiro\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Check column names to ensure correct splitting\n",
        "print(\"\\nColumns in the dataset:\")\n",
        "print(data.columns)\n",
        "\n",
        "# # Separate features and labels\n",
        "# # Use .copy() to avoid SettingWithCopyWarning\n",
        "# X = data.drop(columns=['label']).copy()  # Drop label column for features\n",
        "# y = data['label'].copy()  # Use label column for target\n",
        "\n",
        "# # # Train-test split with stratification\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Verify split\n",
        "print(\"\\nTrain-Test Split:\")\n",
        "print(f\"Train set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"Klasseverdeling in train:\\n{y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Klasseverdeling in test:\\n{y_test.value_counts(normalize=True)}\")\n",
        "\n",
        "# Separate benign and malignant samples\n",
        "benign = data[data['label'] == 'benign']\n",
        "malignant = data[data['label'] == 'malignant']\n",
        "\n",
        "benign.to_csv('benign_data.csv', index=True)\n",
        "malignant.to_csv('malignant_data.csv', index=True)\n",
        "\n",
        "# Perform statistical analysis\n",
        "results = []\n",
        "significant_features = []\n",
        "\n",
        "# Loop through all features except 'label'\n",
        "for feature in X.columns:\n",
        "    # Data for current feature\n",
        "    benign_values = benign[feature].dropna()\n",
        "    malignant_values = malignant[feature].dropna()\n",
        "\n",
        "    # Normality test (Shapiro-Wilk test, p < 0.05 means NOT normally distributed)\n",
        "    _, p_benign = shapiro(benign_values)\n",
        "    _, p_malignant = shapiro(malignant_values)\n",
        "\n",
        "    # Determine which test to use\n",
        "    if p_benign > 0.05 and p_malignant > 0.05:  # Both distributions are normal\n",
        "        test_type = \"t-test\"\n",
        "        stat, p_value = ttest_ind(benign_values, malignant_values, equal_var=False)  # Welch's t-test\n",
        "    else:\n",
        "        test_type = \"Mann-Whitney U-test\"\n",
        "        stat, p_value = mannwhitneyu(benign_values, malignant_values, alternative='two-sided')\n",
        "\n",
        "    # Save results\n",
        "    result_entry = {\n",
        "        \"Feature\": feature, \n",
        "        \"Test\": test_type, \n",
        "        \"p_value\": p_value\n",
        "    }\n",
        "    results.append(result_entry)\n",
        "\n",
        "    # Check for significance (p <= 0.05)\n",
        "    if p_value <= 0.05:\n",
        "        significant_entry = result_entry.copy()\n",
        "        significant_entry['benign_mean'] = benign_values.mean()\n",
        "        significant_entry['malignant_mean'] = malignant_values.mean()\n",
        "        significant_entry['benign_std'] = benign_values.std()\n",
        "        significant_entry['malignant_std'] = malignant_values.std()\n",
        "        significant_features.append(significant_entry)\n",
        "\n",
        "# Convert to DataFrames\n",
        "results_df = pd.DataFrame(results)\n",
        "significant_features_df = pd.DataFrame(significant_features)\n",
        "\n",
        "# Multiple testing correction (False Discovery Rate - Benjamini-Hochberg)\n",
        "_, p_corrected, _, _ = multipletests(results_df[\"p_value\"], method='fdr_bh')\n",
        "results_df[\"p_value_corrected\"] = p_corrected\n",
        "\n",
        "# Sort significant features by p-value\n",
        "significant_features_df = significant_features_df.sort_values(by=\"p_value\")\n",
        "\n",
        "# Print and save results\n",
        "print(\"\\nTotal Significant Features:\")\n",
        "print(significant_features_df)\n",
        "\n",
        "# Optional: Save to CSV\n",
        "significant_features_df.to_csv('significant_features.csv', index=False)\n",
        "print(\"\\nSignificant features saved to 'significant_features.csv'\")\n",
        "\n",
        "# Quick summary\n",
        "print(f\"\\nNumber of significant features: {len(significant_features_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
