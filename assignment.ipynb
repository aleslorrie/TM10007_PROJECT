{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1kxzuvBYl0e"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NE_fTbKGe5z",
        "outputId": "41d8a998-c9c9-49c0-c753-ce6b03f90d93"
      },
      "outputs": [],
      "source": [
        "#Load packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import datasets as ds\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Classifiers --> later bijwerken welke we gebruiken\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Importing Data loading functions. Uncomment the one you want to use\n",
        "from worcliver.load_data import load_data\n",
        "\n",
        "from scipy.stats import ttest_ind, mannwhitneyu, shapiro\n",
        "from statsmodels.stats.multitest import multipletests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "data = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Presentation of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 186\n",
            "The number of columns: 494\n",
            "First five rows of the dataset:\n",
            "                 label  PREDICT_original_sf_compactness_avg_2.5D  \\\n",
            "ID                                                                 \n",
            "Liver-001_0     benign                                  0.878471   \n",
            "Liver-002_0     benign                                  0.878945   \n",
            "Liver-003_0     benign                                  0.766162   \n",
            "Liver-004_0  malignant                                  0.825737   \n",
            "Liver-005_0  malignant                                  0.828831   \n",
            "\n",
            "             PREDICT_original_sf_compactness_std_2.5D  \\\n",
            "ID                                                      \n",
            "Liver-001_0                                  0.023468   \n",
            "Liver-002_0                                  0.039922   \n",
            "Liver-003_0                                  0.064140   \n",
            "Liver-004_0                                  0.062047   \n",
            "Liver-005_0                                  0.062635   \n",
            "\n",
            "             PREDICT_original_sf_rad_dist_avg_2.5D  \\\n",
            "ID                                                   \n",
            "Liver-001_0                              39.716446   \n",
            "Liver-002_0                              17.254964   \n",
            "Liver-003_0                              33.803937   \n",
            "Liver-004_0                              43.053826   \n",
            "Liver-005_0                              28.420403   \n",
            "\n",
            "             PREDICT_original_sf_rad_dist_std_2.5D  \\\n",
            "ID                                                   \n",
            "Liver-001_0                               4.650388   \n",
            "Liver-002_0                               2.741507   \n",
            "Liver-003_0                               7.191043   \n",
            "Liver-004_0                               5.973366   \n",
            "Liver-005_0                               2.739982   \n",
            "\n",
            "             PREDICT_original_sf_roughness_avg_2.5D  \\\n",
            "ID                                                    \n",
            "Liver-001_0                                4.840280   \n",
            "Liver-002_0                                6.521991   \n",
            "Liver-003_0                                6.634326   \n",
            "Liver-004_0                                8.340360   \n",
            "Liver-005_0                                5.531189   \n",
            "\n",
            "             PREDICT_original_sf_roughness_std_2.5D  \\\n",
            "ID                                                    \n",
            "Liver-001_0                                3.599071   \n",
            "Liver-002_0                                2.687448   \n",
            "Liver-003_0                                3.101814   \n",
            "Liver-004_0                                4.981466   \n",
            "Liver-005_0                                1.825404   \n",
            "\n",
            "             PREDICT_original_sf_convexity_avg_2.5D  \\\n",
            "ID                                                    \n",
            "Liver-001_0                                0.975855   \n",
            "Liver-002_0                                0.989684   \n",
            "Liver-003_0                                0.964987   \n",
            "Liver-004_0                                0.965802   \n",
            "Liver-005_0                                0.946483   \n",
            "\n",
            "             PREDICT_original_sf_convexity_std_2.5D  \\\n",
            "ID                                                    \n",
            "Liver-001_0                                0.008789   \n",
            "Liver-002_0                                0.006644   \n",
            "Liver-003_0                                0.020437   \n",
            "Liver-004_0                                0.016256   \n",
            "Liver-005_0                                0.028237   \n",
            "\n",
            "             PREDICT_original_sf_cvar_avg_2.5D  ...  \\\n",
            "ID                                              ...   \n",
            "Liver-001_0                           0.016611  ...   \n",
            "Liver-002_0                           0.026773  ...   \n",
            "Liver-003_0                           0.045053  ...   \n",
            "Liver-004_0                           0.019045  ...   \n",
            "Liver-005_0                           0.009983  ...   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_median_WL3_N5  \\\n",
            "ID                                                            \n",
            "Liver-001_0                                        0.000000   \n",
            "Liver-002_0                                        0.000000   \n",
            "Liver-003_0                                        0.084954   \n",
            "Liver-004_0                                        0.000000   \n",
            "Liver-005_0                                        0.000000   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_std_WL3_N5  \\\n",
            "ID                                                         \n",
            "Liver-001_0                                     0.101850   \n",
            "Liver-002_0                                     0.173083   \n",
            "Liver-003_0                                     0.171358   \n",
            "Liver-004_0                                     0.088297   \n",
            "Liver-005_0                                     0.133324   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_skewness_WL3_N5  \\\n",
            "ID                                                              \n",
            "Liver-001_0                                          2.616758   \n",
            "Liver-002_0                                          1.553137   \n",
            "Liver-003_0                                          1.032906   \n",
            "Liver-004_0                                          3.265959   \n",
            "Liver-005_0                                          2.029068   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_kurtosis_WL3_N5  \\\n",
            "ID                                                              \n",
            "Liver-001_0                                          6.864153   \n",
            "Liver-002_0                                          1.295746   \n",
            "Liver-003_0                                          0.173105   \n",
            "Liver-004_0                                         11.372725   \n",
            "Liver-005_0                                          3.703768   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_peak_WL3_N5  \\\n",
            "ID                                                          \n",
            "Liver-001_0                                           0.0   \n",
            "Liver-002_0                                           0.0   \n",
            "Liver-003_0                                           0.0   \n",
            "Liver-004_0                                           0.0   \n",
            "Liver-005_0                                           0.0   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_peak_position_WL3_N5  \\\n",
            "ID                                                                   \n",
            "Liver-001_0                                                  0       \n",
            "Liver-002_0                                                  0       \n",
            "Liver-003_0                                                  0       \n",
            "Liver-004_0                                                  0       \n",
            "Liver-005_0                                                  0       \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_range_WL3_N5  \\\n",
            "ID                                                           \n",
            "Liver-001_0                                       0.390248   \n",
            "Liver-002_0                                       0.594234   \n",
            "Liver-003_0                                       0.582798   \n",
            "Liver-004_0                                       0.362900   \n",
            "Liver-005_0                                       0.495562   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_energy_WL3_N5  \\\n",
            "ID                                                            \n",
            "Liver-001_0                                      449.839556   \n",
            "Liver-002_0                                      235.252263   \n",
            "Liver-003_0                                     3163.278682   \n",
            "Liver-004_0                                      983.532471   \n",
            "Liver-005_0                                      294.506372   \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \\\n",
            "ID                                                                    \n",
            "Liver-001_0                                           0.007130        \n",
            "Liver-002_0                                           0.187216        \n",
            "Liver-003_0                                           0.269640        \n",
            "Liver-004_0                                           0.000000        \n",
            "Liver-005_0                                           0.110388        \n",
            "\n",
            "             PREDICT_original_phasef_phasesym_entropy_WL3_N5  \n",
            "ID                                                            \n",
            "Liver-001_0                                        12.746479  \n",
            "Liver-002_0                                        10.778987  \n",
            "Liver-003_0                                        14.878373  \n",
            "Liver-004_0                                        13.937997  \n",
            "Liver-005_0                                        11.764256  \n",
            "\n",
            "[5 rows x 494 columns] \n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 186 entries, Liver-001_0 to Liver-186_0\n",
            "Columns: 494 entries, label to PREDICT_original_phasef_phasesym_entropy_WL3_N5\n",
            "dtypes: float64(468), int64(25), object(1)\n",
            "memory usage: 723.4+ KB\n",
            "None \n",
            "\n",
            "Summary statistics:\n",
            "       PREDICT_original_sf_compactness_avg_2.5D  \\\n",
            "count                                186.000000   \n",
            "mean                                   0.808754   \n",
            "std                                    0.070161   \n",
            "min                                    0.549046   \n",
            "25%                                    0.773570   \n",
            "50%                                    0.824074   \n",
            "75%                                    0.857698   \n",
            "max                                    0.926346   \n",
            "\n",
            "       PREDICT_original_sf_compactness_std_2.5D  \\\n",
            "count                                186.000000   \n",
            "mean                                   0.071922   \n",
            "std                                    0.047649   \n",
            "min                                    0.004729   \n",
            "25%                                    0.041594   \n",
            "50%                                    0.056596   \n",
            "75%                                    0.082090   \n",
            "max                                    0.245769   \n",
            "\n",
            "       PREDICT_original_sf_rad_dist_avg_2.5D  \\\n",
            "count                             186.000000   \n",
            "mean                               30.933690   \n",
            "std                                14.209702   \n",
            "min                                 9.648695   \n",
            "25%                                19.942274   \n",
            "50%                                27.275579   \n",
            "75%                                38.754607   \n",
            "max                                73.610032   \n",
            "\n",
            "       PREDICT_original_sf_rad_dist_std_2.5D  \\\n",
            "count                             186.000000   \n",
            "mean                                4.662412   \n",
            "std                                 2.656027   \n",
            "min                                 1.113733   \n",
            "25%                                 2.762641   \n",
            "50%                                 3.986081   \n",
            "75%                                 6.093413   \n",
            "max                                16.559442   \n",
            "\n",
            "       PREDICT_original_sf_roughness_avg_2.5D  \\\n",
            "count                              186.000000   \n",
            "mean                                 8.502448   \n",
            "std                                  3.301010   \n",
            "min                                  2.310309   \n",
            "25%                                  6.407817   \n",
            "50%                                  7.850429   \n",
            "75%                                 10.244457   \n",
            "max                                 21.955618   \n",
            "\n",
            "       PREDICT_original_sf_roughness_std_2.5D  \\\n",
            "count                              186.000000   \n",
            "mean                                 3.342782   \n",
            "std                                  2.233298   \n",
            "min                                  0.152609   \n",
            "25%                                  1.925876   \n",
            "50%                                  2.826361   \n",
            "75%                                  4.118141   \n",
            "max                                 15.637597   \n",
            "\n",
            "       PREDICT_original_sf_convexity_avg_2.5D  \\\n",
            "count                              186.000000   \n",
            "mean                                 0.957851   \n",
            "std                                  0.029453   \n",
            "min                                  0.790738   \n",
            "25%                                  0.950779   \n",
            "50%                                  0.963595   \n",
            "75%                                  0.975330   \n",
            "max                                  1.001046   \n",
            "\n",
            "       PREDICT_original_sf_convexity_std_2.5D  \\\n",
            "count                              186.000000   \n",
            "mean                                 0.032693   \n",
            "std                                  0.031656   \n",
            "min                                  0.003572   \n",
            "25%                                  0.016380   \n",
            "50%                                  0.022517   \n",
            "75%                                  0.035129   \n",
            "max                                  0.199697   \n",
            "\n",
            "       PREDICT_original_sf_cvar_avg_2.5D  PREDICT_original_sf_cvar_std_2.5D  \\\n",
            "count                         186.000000                         186.000000   \n",
            "mean                            0.026943                           0.015394   \n",
            "std                             0.014903                           0.011985   \n",
            "min                             0.007132                           0.001949   \n",
            "25%                             0.015875                           0.007571   \n",
            "50%                             0.023180                           0.011660   \n",
            "75%                             0.034253                           0.018561   \n",
            "max                             0.094500                           0.081094   \n",
            "\n",
            "       ...  PREDICT_original_phasef_phasesym_median_WL3_N5  \\\n",
            "count  ...                                      186.000000   \n",
            "mean   ...                                        0.003918   \n",
            "std    ...                                        0.018269   \n",
            "min    ...                                        0.000000   \n",
            "25%    ...                                        0.000000   \n",
            "50%    ...                                        0.000000   \n",
            "75%    ...                                        0.000000   \n",
            "max    ...                                        0.182629   \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_std_WL3_N5  \\\n",
            "count                                   186.000000   \n",
            "mean                                      0.117450   \n",
            "std                                       0.036035   \n",
            "min                                       0.022161   \n",
            "25%                                       0.094277   \n",
            "50%                                       0.117008   \n",
            "75%                                       0.139185   \n",
            "max                                       0.206225   \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_skewness_WL3_N5  \\\n",
            "count                                        186.000000   \n",
            "mean                                           2.685524   \n",
            "std                                            1.584082   \n",
            "min                                            0.517983   \n",
            "25%                                            1.736278   \n",
            "50%                                            2.425099   \n",
            "75%                                            3.147908   \n",
            "max                                           11.394947   \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_kurtosis_WL3_N5  \\\n",
            "count                                        186.000000   \n",
            "mean                                          10.319765   \n",
            "std                                           19.430363   \n",
            "min                                           -0.850033   \n",
            "25%                                            2.333788   \n",
            "50%                                            5.755874   \n",
            "75%                                           10.266871   \n",
            "max                                          152.451063   \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_peak_WL3_N5  \\\n",
            "count                                         186.0   \n",
            "mean                                            0.0   \n",
            "std                                             0.0   \n",
            "min                                             0.0   \n",
            "25%                                             0.0   \n",
            "50%                                             0.0   \n",
            "75%                                             0.0   \n",
            "max                                             0.0   \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_peak_position_WL3_N5  \\\n",
            "count                                              186.0       \n",
            "mean                                                 0.0       \n",
            "std                                                  0.0       \n",
            "min                                                  0.0       \n",
            "25%                                                  0.0       \n",
            "50%                                                  0.0       \n",
            "75%                                                  0.0       \n",
            "max                                                  0.0       \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_range_WL3_N5  \\\n",
            "count                                     186.000000   \n",
            "mean                                        0.434644   \n",
            "std                                         0.110802   \n",
            "min                                         0.017016   \n",
            "25%                                         0.383358   \n",
            "50%                                         0.450890   \n",
            "75%                                         0.502443   \n",
            "max                                         0.647253   \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_energy_WL3_N5  \\\n",
            "count                                      186.000000   \n",
            "mean                                       831.783444   \n",
            "std                                       1209.357229   \n",
            "min                                          1.881053   \n",
            "25%                                        138.612083   \n",
            "50%                                        326.415008   \n",
            "75%                                        985.647567   \n",
            "max                                       7624.462235   \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \\\n",
            "count                                         186.000000        \n",
            "mean                                            0.079940        \n",
            "std                                             0.089738        \n",
            "min                                             0.000000        \n",
            "25%                                             0.000000        \n",
            "50%                                             0.045491        \n",
            "75%                                             0.138077        \n",
            "max                                             0.356156        \n",
            "\n",
            "       PREDICT_original_phasef_phasesym_entropy_WL3_N5  \n",
            "count                                       186.000000  \n",
            "mean                                         12.165591  \n",
            "std                                           1.964496  \n",
            "min                                           6.097990  \n",
            "25%                                          10.761014  \n",
            "50%                                          12.154106  \n",
            "75%                                          13.648707  \n",
            "max                                          16.720278  \n",
            "\n",
            "[8 rows x 493 columns] \n",
            "\n",
            "Total missing values in the dataset: 0\n",
            "\n",
            "Missing values per column:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "Number of categorical columns: 1\n",
            "Number of numerical columns: 493\n",
            "\n",
            "Label distribution:\n",
            "malignant    94\n",
            "benign       92\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Description of the data\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Display basic info\n",
        "print(\"First five rows of the dataset:\")\n",
        "print(data.head(), \"\\n\")\n",
        "\n",
        "print(\"Dataset info:\")\n",
        "print(data.info(), \"\\n\")\n",
        "\n",
        "print(\"Summary statistics:\")\n",
        "print(data.describe(), \"\\n\")\n",
        "\n",
        "# Counting missing values\n",
        "missing_values = data.isnull().sum()\n",
        "total_missing = missing_values.sum()\n",
        "\n",
        "print(f\"Total missing values in the dataset: {total_missing}\\n\")\n",
        "print(f\"Missing values per column:\\n{missing_values[missing_values > 0]}\\n\")\n",
        "\n",
        "# Counting categorical and numerical columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "numerical_columns = data.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "print(f\"Number of categorical columns: {len(categorical_columns)}\")\n",
        "print(f\"Number of numerical columns: {len(numerical_columns)}\\n\")\n",
        "\n",
        "# Count of each label (benign/malignant)\n",
        "label_counts = data['label'].value_counts()\n",
        "\n",
        "print(\"Label distribution:\")\n",
        "print(label_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Changing labels malignant and benign to 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "#changing string (malignant or benign) to 0 or 1\n",
        "num_data = data.copy()\n",
        "\n",
        "# Transform labels: benign -> 1, malignant -> 0\n",
        "num_data['label'] = num_data['label'].map({'benign': 1, 'malignant': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Splitting data in train and test test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of the train data: (148, 494)\n",
            "The shape of the test data: (38, 494)\n"
          ]
        }
      ],
      "source": [
        "#Splitting data in test and train set \n",
        "y = num_data['label']\n",
        "x = num_data[:]\n",
        "\n",
        "#x is features, y  = maligne / benign\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "#print the shape of the data sets  \n",
        "print(f'The shape of the train data: {x_train.shape}')\n",
        "print(f'The shape of the test data: {x_test.shape}')\n",
        "\n",
        "x_train.to_csv('x_train.csv', index=False) \n",
        "x_test.to_csv('x_test.csv', index=False) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Selecting significant features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ellen\\Nieuwe_map\\envs\\KT-2023\\lib\\site-packages\\scipy\\stats\\morestats.py:1757: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
            "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of significant features: 154\n"
          ]
        }
      ],
      "source": [
        "# Select significant features\n",
        "# Add the label column back to x_train\n",
        "x_train_with_label = x_train.copy()\n",
        "x_train_with_label['label'] = y_train\n",
        "\n",
        "# Separate benign and malignant samples in training data\n",
        "benign = x_train_with_label[x_train_with_label['label'] == 1]\n",
        "malignant = x_train_with_label[x_train_with_label['label'] == 0]\n",
        "\n",
        "x_train_with_label.to_csv('x_train_label.csv', index=False) \n",
        "# Perform statistical analysis\n",
        "features = []\n",
        "sig_features = []\n",
        "\n",
        "# Loop through all features except 'label'\n",
        "for feature in x_train_with_label.columns:\n",
        "    if feature == 'label':  # Skip the label column\n",
        "        continue\n",
        "        \n",
        "    # Data for current feature\n",
        "    benign_values = benign[feature].dropna()\n",
        "    malignant_values = malignant[feature].dropna()\n",
        "    \n",
        "    # Normality test (Shapiro-Wilk test, p < 0.05 means not normally distributed)\n",
        "    _, p_benign = shapiro(benign_values)\n",
        "    _, p_malignant = shapiro(malignant_values)\n",
        "    \n",
        "    # Determine which test to use\n",
        "    if p_benign > 0.05 and p_malignant > 0.05:  # Both distributions are normal\n",
        "        test_type = \"t-test\"\n",
        "        stat, p_value = ttest_ind(benign_values, malignant_values, equal_var=False)  # Welch's t-test\n",
        "    else:\n",
        "        test_type = \"Mann-Whitney U-test\"\n",
        "        stat, p_value = mannwhitneyu(benign_values, malignant_values, alternative='two-sided')\n",
        "    \n",
        "    # Save results\n",
        "    feature_entry = {\n",
        "        \"Feature\": feature,\n",
        "        \"Test\": test_type,\n",
        "        \"p_value\": p_value\n",
        "    }\n",
        "    features.append(feature_entry)\n",
        "    \n",
        "    # Check for significance (p <= 0.05)\n",
        "    if p_value <= 0.05:\n",
        "        sig_entry = feature_entry.copy()\n",
        "        # sig_entry['benign_mean'] = benign_values.mean()\n",
        "        # sig_entry['malignant_mean'] = malignant_values.mean()\n",
        "        # sig_entry['benign_std'] = benign_values.std()\n",
        "        # sig_entry['malignant_std'] = malignant_values.std()\n",
        "        sig_features.append(sig_entry)\n",
        "\n",
        "# Convert to DataFrames\n",
        "features_df = pd.DataFrame(features)\n",
        "sig_features_df = pd.DataFrame(sig_features)\n",
        "\n",
        "# Multiple testing correction (False Discovery Rate - Benjamini-Hochberg)\n",
        "if not features_df.empty:\n",
        "    reject, p_corrected, alphacSidak, alphacBonf = multipletests(features_df[\"p_value\"], method='fdr_bh')\n",
        "    features_df[\"p_value_corrected\"] = p_corrected\n",
        "\n",
        "# Sort significant features by p-value only if there are significant features\n",
        "if not sig_features_df.empty:\n",
        "    sig_features_df = sig_features_df.sort_values(by=\"p_value\")\n",
        "\n",
        "# Print and save results\n",
        "# print(\"\\nTotal Significant Features:\")\n",
        "# print(sig_features_df)\n",
        "print(f\"\\nNumber of significant features: {len(sig_features_df)}\")\n",
        "\n",
        "# Get the list of significant feature names\n",
        "sig_feature_names = sig_features_df['Feature'].tolist() if not sig_features_df.empty else []\n",
        "\n",
        "# Select only significant features for training data if there are any\n",
        "if sig_feature_names:\n",
        "    x_train_sig = x_train[sig_feature_names].copy()\n",
        "    # Save results to CSV\n",
        "    x_train_sig.to_csv('x_train_sig.csv', index=False)\n",
        "else:\n",
        "    print(\"No significant features found. Cannot create x_train_sig.\")\n",
        "\n",
        "# Save results to CSV\n",
        "# features_df.to_csv('features.csv', index=False)\n",
        "sig_features_df.to_csv('sig_features_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The ammount of normal distributed features is: 77\n",
            " The ammount of normal distributed features (p>0.05) 39\n",
            " Percentages of usable features for lineair classifier: 7.894736842105263\n"
          ]
        }
      ],
      "source": [
        "# Linear classifier\n",
        "# Test how many feautures are normal distributed and covariances equal (p > 0.05)\n",
        "\n",
        "#From features_df, sum how many t test used, i.e. are normal distributed from all features\n",
        "normal_distributed = features_df.loc[features_df['Test'] == 't-test', 'Test'].count() \n",
        "print(f' The ammount of normal distributed features is: {normal_distributed}')\n",
        "\n",
        "#the ammount of normal distibuted from significant features \n",
        "normal_distributed_sig = sig_features_df.loc[features_df['Test'] == 't-test', 'Test'].count() \n",
        "normal_distributed_non_sig = normal_distributed - normal_distributed_sig\n",
        "print(f' The ammount of normal distributed features (p>0.05) {normal_distributed_non_sig}')\n",
        "\n",
        "#Percentage of usable featrues for lineair classifier\n",
        "print(f' Percentages of usable features for lineair classifier: {normal_distributed_non_sig/(len(data.columns))*100}')\n",
        "\n",
        "\n",
        "#hier wordt de lineaire classif gemaakt, bepalen of we dat willen met 52\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda = lda.fit(x_train, y_train)\n",
        "y_pred_lda = lda.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quadratic classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The ammount of normal distributed features is: 77\n",
            " The ammount of normal distributed features (p < 0.05) is: 38\n",
            " Percentages of usable features for lineair classifier: 7.6923076923076925\n"
          ]
        }
      ],
      "source": [
        "# Quadratic classifier\n",
        "# Test how many feautures are normal distributed and covariances not equal (p < 0.05)\n",
        "\n",
        "#From features_df, sum how many t test used, i.e. are normal distributed from all features\n",
        "normal_distributed = features_df.loc[features_df['Test'] == 't-test', 'Test'].count() \n",
        "print(f' The ammount of normal distributed features is: {normal_distributed}')\n",
        "\n",
        "#the ammount of normal distibuted from non significant features \n",
        "normal_distributed_sig = sig_features_df.loc[features_df['Test'] == 't-test', 'Test'].count() \n",
        "print(f' The ammount of normal distributed features (p < 0.05) is: {normal_distributed_sig}')\n",
        "\n",
        "#Percentage of usable featrues for quadratic classifier\n",
        "print(f' Percentages of usable features for lineair classifier: {normal_distributed_sig/(len(data.columns))*100}')\n",
        "\n",
        "# quadratic uitvoeren, later wss weg\n",
        "#q_clas = QuadraticDiscriminantAnalysis()\n",
        "#q_clas = q_clas.fit(x_train, y_train)\n",
        "#q_clas_pred = q_clas.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Voorbeeld functie loss funcite (voor lda) --> niet werkend op lda, code later aanpassen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [148, 38]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#for lda, X1, Y1 in zip(lda, x_train, y_train):\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m auc\u001b[38;5;241m=\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mroc_auc_score(y_train, y_pred_lda)\n\u001b[0;32m      3\u001b[0m accuracy\u001b[38;5;241m=\u001b[39mmetrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_train, y_pred_lda)\n\u001b[0;32m      4\u001b[0m F1\u001b[38;5;241m=\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mf1_score(y_train,y_pred_lda)\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:641\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    639\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[0;32m    640\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    642\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    643\u001b[0m         y_true,\n\u001b[0;32m    644\u001b[0m         y_score,\n\u001b[0;32m    645\u001b[0m         average,\n\u001b[0;32m    646\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    650\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    651\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    655\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py:69\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m     71\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     72\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:388\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    379\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    380\u001b[0m         (\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class is present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m         UndefinedMetricWarning,\n\u001b[0;32m    385\u001b[0m     )\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m--> 388\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1150\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1047\u001b[0m     {\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m ):\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \n\u001b[0;32m   1061\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1150\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m   1151\u001b[0m         y_true, y_score, pos_label\u001b[38;5;241m=\u001b[39mpos_label, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[0;32m   1152\u001b[0m     )\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1161\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:820\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m--> 820\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    821\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m    822\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
            "File \u001b[1;32mc:\\Users\\manon\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    478\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [148, 38]"
          ]
        }
      ],
      "source": [
        "#for lda, X1, Y1 in zip(lda, x_train, y_train):\n",
        "auc=metrics.roc_auc_score(y_train, y_pred_lda)\n",
        "accuracy=metrics.accuracy_score(y_train, y_pred_lda)\n",
        "F1=metrics.f1_score(y_train,y_pred_lda)\n",
        "precision=metrics.precision_score(y_train,y_pred_lda)\n",
        "recall=metrics.recall_score(y_train, y_pred_lda)\n",
        "\n",
        "    # accuracy, AUC, f1score, precision, recall\n",
        "print(type(lda))\n",
        "print('Acc:' +str(accuracy))\n",
        "print('AUC:' +str(auc))\n",
        "print('F1:' +str(F1))\n",
        "print('precision:' +str(precision))\n",
        "print('recall:' +str(recall))\n",
        "\n",
        "for learning_rate in [0.001, 0.01, 0.1, 0.5]:\n",
        "\n",
        "    print(f\"Training with learning rate {learning_rate}\")\n",
        "    print(\"Training set score: %f\" % lda.score(x_train, y_train))\n",
        "    print(\"Test set score: %f\" % lda.score(x_test, y_test))\n",
        "\n",
        "    plt.plot(lda.loss_curve_, label=f'lr = {learning_rate}')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.83783784 0.78378378 0.81081081 0.64864865]\n"
          ]
        }
      ],
      "source": [
        "# random forest code\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=10, criterion='gini', min_samples_split=2)\n",
        "#rf.fit(x_train, y_train)\n",
        "validation_rf = cross_val_score(estimator=rf, X=x_train, y=y_train, cv= 4)\n",
        "print(validation_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculate mean and std of individual classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                          mean          std\n",
            "label                                                 1.000000     0.000000\n",
            "PREDICT_original_sf_compactness_avg_2.5D              0.810147     0.077220\n",
            "PREDICT_original_sf_compactness_std_2.5D              0.066376     0.050309\n",
            "PREDICT_original_sf_rad_dist_avg_2.5D                28.506844    12.658553\n",
            "PREDICT_original_sf_rad_dist_std_2.5D                 4.475117     2.573123\n",
            "...                                                        ...          ...\n",
            "PREDICT_original_phasef_phasesym_peak_position_...    0.000000     0.000000\n",
            "PREDICT_original_phasef_phasesym_range_WL3_N5         0.429725     0.106987\n",
            "PREDICT_original_phasef_phasesym_energy_WL3_N5      709.573837  1157.150564\n",
            "PREDICT_original_phasef_phasesym_quartile_range...    0.086281     0.094606\n",
            "PREDICT_original_phasef_phasesym_entropy_WL3_N5      11.905744     1.959428\n",
            "\n",
            "[494 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#Decription \n",
        "## Dit nog aanpassen naar berekenen op basis van 'label' ipv deze nieuwe csv files\n",
        "# Mean\n",
        "benign_mean = benign.mean(numeric_only=True)\n",
        "malignant_mean = malignant.mean(numeric_only=True)\n",
        "\n",
        "# Standard deviation\n",
        "benign_std = benign.std(numeric_only=True)\n",
        "malignant_std = malignant.std(numeric_only=True)\n",
        "\n",
        "#Print statistics\n",
        "benign_stats = pd.DataFrame({\n",
        "    'mean': benign.mean(numeric_only=True),\n",
        "    'std': benign.std(numeric_only=True)\n",
        "})\n",
        "print(benign_stats)\n",
        "benign_stats.T.to_csv('benign_stats.csv')\n",
        "\n",
        "\n",
        "malignant_stats = pd.DataFrame({\n",
        "    'mean': malignant.mean(numeric_only=True),\n",
        "    'std': malignant.std(numeric_only=True)\n",
        "})\n",
        "malignant_stats.T.to_csv('malignant_stats.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
